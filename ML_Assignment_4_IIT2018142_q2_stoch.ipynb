{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from csv import DictReader\n",
    "import random \n",
    "def extract():\n",
    "    file = open('processed_cleveland .csv', 'r')\n",
    "    file1 = DictReader(file)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in file1:\n",
    "        x.append([1.0,float(i['age']),float(i['sex'])])\n",
    "        y.append([float(i['num'])])\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(len(x)):\n",
    "        if len(x_train) < 0.7 * len(x):\n",
    "            x_train.append(x[i])\n",
    "            y_train.append(y[i])\n",
    "            /#print(x_train,y_train)\n",
    "        else:\n",
    "            x_test.append(x[i])\n",
    "            y_test.append(y[i])\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getG(thetax):\n",
    "    return (1 / (1 + np.exp(-1 * thetax)))\n",
    "def stochasticGradientDescent(x, y, theta, numIterations,alpha):\n",
    "    m = len(x)\n",
    "    for i in range(0, numIterations):\n",
    "        for k in range(m):\n",
    "            j = random.randrange(0,m-1)\n",
    "            start = j\n",
    "            end = j+1\n",
    "            X = x[start:end]\n",
    "            Y = y[start:end]\n",
    "            Transpose = np.transpose(X)\n",
    "            hypothesis = getG(np.dot(X, theta))\n",
    "            loss = hypothesis - Y\n",
    "            gradient = np.dot(Transpose, loss) / m\n",
    "            theta = theta - alpha * gradient\n",
    "            #print(theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic without feature scaling\n",
      "[[0.99453498]\n",
      " [0.71289352]\n",
      " [0.99671915]]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "Error %age:  52.22222222222223 %\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = extract()\n",
    "ones = np.ones((len(x_test),1))\n",
    "theta = [[1],[1],[1]]\n",
    "num_iterations = 1000\n",
    "alpha =0.00001\n",
    "print(\"Stochastic without feature scaling\")\n",
    "theta= stochasticGradientDescent(x_train,y_train,theta,num_iterations,alpha)\n",
    "print(theta)\n",
    "y_pred = getG(np.dot(x_test,theta)) \n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]>= 0.5):\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "error = 0 \n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        print(y_pred[i],y_test[i])\n",
    "        error = error+1\n",
    "error = error/len(y_test)*100\n",
    "print(\"Error %age: \",error,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent with feature scaling\n",
      "[[0.99731321]\n",
      " [1.00016817]\n",
      " [1.00015424]]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "[1.] [0.0]\n",
      "Error %age:  52.22222222222223 %\n"
     ]
    }
   ],
   "source": [
    "def featureScaling(x_train):\n",
    "    min_x1 = x_train[0][1]\n",
    "    min_x2 = x_train[0][2]\n",
    "    max_x1 = x_train[0][1]\n",
    "    max_x2 = x_train[0][2]\n",
    "    x_train_scaled = x_train\n",
    "    avg_x1 = 0\n",
    "    avg_x2 = 0\n",
    "    for i in range(len(x_train)):\n",
    "        min_x1 = min(x_train[i][1],min_x1)\n",
    "        min_x2 = min(x_train[i][2],min_x2)\n",
    "        avg_x1 += x_train[i][1]\n",
    "        avg_x2 += x_train[i][2]\n",
    "        max_x1 = max(x_train[i][1],max_x1)\n",
    "        max_x2 = max(x_train[i][2],max_x2)\n",
    "    avg_x1 = avg_x1/len(x_train)\n",
    "    avg_x2 = avg_x2/len(x_train)\n",
    "    for i in range(len(x_train_scaled)):\n",
    "        x_train_scaled[i][1] = (x_train_scaled[i][1] - avg_x1)/(max_x1-min_x1)\n",
    "        x_train_scaled[i][2] = (x_train_scaled[i][2] - avg_x2)/(max_x2-min_x2)\n",
    "    return x_train_scaled\n",
    "x_train_scaled = featureScaling(x_train)\n",
    "theta = [[1],[1],[1]]\n",
    "print(\"Stochastic Gradient Descent with feature scaling\")\n",
    "theta= stochasticGradientDescent(x_train_scaled,y_train,theta,num_iterations,alpha)\n",
    "print(theta)\n",
    "y_pred = getG(np.dot(x_test,theta)) \n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]>= 0.5):\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "error = 0 \n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        print(y_pred[i],y_test[i])\n",
    "        error = error+1\n",
    "error = error/len(y_test)*100\n",
    "print(\"Error %age: \",error,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
